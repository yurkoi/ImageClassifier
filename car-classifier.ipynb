{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Классификация изображений\n\n### Основная идея этого решения: взять предобученую на ImageNet сеть EfficientNetB6 и дообучить под нашу задачу. \n\nВ ноутбуке будут использоваться такие приемы, как:\n* аугментация при помощи библиотеки albumentations\n* политика One Cycle Policy для Learning Rate\n* аугментация изображений из тестовой выборки - test time augmentation (TTA)"},{"metadata":{},"cell_type":"markdown","source":"# Установка и импорт необходимых библиотек"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обновление tensorflow\n!pip install tensorflow --upgrade\n# Загрузка модели efficientnet\n!pip install -q efficientnet\n# Загружаем обвязку под keras для использования продвинутых библиотек аугментации, например, albuminations\n!pip install git+https://github.com/mjkvaak/ImageDataAugmentor","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport scipy.io\nimport tarfile\nimport csv\nimport sys\nimport os\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.models as M\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.callbacks as C\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras import optimizers\nimport efficientnet.tfkeras as efn\nimport zipfile\n\nfrom ImageDataAugmentor.image_data_augmentor import *\nimport albumentations\n\nfrom sklearn.model_selection import train_test_split\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#увеличим дефолтный размер графиков\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#графики в svg выглядят более четкими\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"../input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', keras.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Основные настройки"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Batch size\nBATCH_SIZE           = 8 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\nBATCH_SIZE_STEP4     = 4\n\n# Epochs\nEPOCHS_STEP1         = 15  # эпох на обучение\nEPOCHS_STEP2         = 10  # эпох на обучение  \nEPOCHS_STEP3         = 8  # эпох на обучение  \nEPOCHS_STEP4         = 8  # эпох на обучение  \n\n# Learning Rates\nLR_STEP1             = 1e-3\nLR_STEP2             = 1e-4\nLR_STEP3             = 1e-5\nLR_STEP4             = 1e-5\n\n# Learning Rate One Cycle Policy\nMAX_MOMENTUM = 0.98\nBASE_MOMENTUM = 0.85\nCYCLICAL_MOMENTUM = True\nAUGMENT = True\nCYCLES = 2.35\n\n# Test-validation split\nVAL_SPLIT            = 0.2 # сколько данных выделяем на тест = 20%\n\nCLASS_NUM            = 10  # количество классов в нашей задаче\nIMG_SIZE             = 250 # какого размера подаем изображения в сеть\nIMG_SIZE_STEP4       = 512\n\nIMG_CHANNELS         = 3   # у RGB 3 канала\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '../input/'\nPATH = \"../working/car/\"\n\n# Создание рабочей директории\nos.makedirs(PATH,exist_ok=False)\n\n# Устанавливаем конкретное значение random seed для воспроизводимости\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA / Анализ данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Category.value_counts()\n# распределение классов достаточно равномерное - это хорошо","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Распаковываем картинки')\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(\"../input/\"+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Пример картинок (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = df.sample(n=16)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n    plt.subplot(4,4, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = df.sample(n=1)\nindex = res['Category'].values[0]\npath = res['Id'].values[0]\n\nimage = PIL.Image.open(PATH+f'/train/{index}/{path}')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Подготовка данных"},{"metadata":{},"cell_type":"markdown","source":"## Аугментация данных"},{"metadata":{},"cell_type":"markdown","source":"Аугментация с использованием библиотеки Albumentations"},{"metadata":{"trusted":true},"cell_type":"code","source":"AUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=250, width=200),\n        albumentations.CenterCrop(height=200, width=250),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n\ntrain_datagen = ImageDataAugmentor(\n        rescale=1./255,\n        augment = AUGMENTATIONS,\n        validation_split=VAL_SPLIT,\n        )\n        \ntest_datagen = ImageDataAugmentor(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Генерация данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Завернем наши данные в генератор:\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import io\n\ndef imshow(image_RGB):\n    io.imshow(image_RGB)\n    io.show()\n\nx,y = train_generator.next()\nprint('Пример картинок из train_generator')\nplt.figure(figsize=(12,8))\n\nfor i in range(0,6):\n    image = x[i]\n    plt.subplot(3,3, i+1)\n    plt.imshow(image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x,y = test_generator.next()\nprint('Пример картинок из test_generator')\nplt.figure(figsize=(12,8))\n\nfor i in range(0,6):\n    image = x[i]\n    plt.subplot(3,3, i+1)\n    plt.imshow(image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Построение модели"},{"metadata":{},"cell_type":"markdown","source":"На момент выполнения задания сеть EfficientNetB7 все ещё является оптимальным выбором, если брать во внимание точность предсказаний и время работы."},{"metadata":{},"cell_type":"markdown","source":"### Загружаем предобученную сеть EfficientNetB7:"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = efn.EfficientNetB7(\n    weights='imagenet', # Подгружаем веса imagenet\n    include_top=False,  # Выходной слой (голову) будем менять т.к. у нас други классы\n    input_shape=input_shape)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Посмотрим на загруженную модель EfficientNetB6\nbase_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для начала заморозим веса EfficientNetB6 и обучим только \"голову\". \n# Делаем это для того, чтобы хорошо обученные признаки на Imagenet не затирались в самом начале нашего обучения\nbase_model.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Устанавливаем \"голову\""},{"metadata":{"trusted":true},"cell_type":"code","source":"model=M.Sequential()\nmodel.add(base_model)\nmodel.add(L.GlobalAveragePooling2D(),) # объединяем все признаки в единый вектор \n\n# Экспериментируем с архитектурой - добавляем ещё один полносвязный слой, dropout и batch-нормализацию\nmodel.add(L.Dense(256, activation='relu'))\nmodel.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\n\nmodel.add(L.Dense(CLASS_NUM, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Смотрим на получившуюся модель\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Количество слоев\nprint(len(model.layers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Количество параметров обучения\nlen(model.trainable_variables)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Статус слоев - будем обучать или нет\nfor layer in model.layers:\n    print(layer, layer.trainable)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Обучение модели"},{"metadata":{},"cell_type":"markdown","source":"## Управление Learning Rate - One Cycle Policy"},{"metadata":{},"cell_type":"markdown","source":"Реализуем one cycle policy. Код взят отсюда: https://www.kaggle.com/robotdreams/one-cycle-policy-with-keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implement One Cycle Policy Algorithm in the Keras Callback Class\n\nfrom sklearn.metrics import log_loss, roc_auc_score, accuracy_score\nfrom keras.losses import binary_crossentropy\nfrom keras.metrics import binary_accuracy\nfrom keras import backend as K\nfrom keras.callbacks import *\n\nclass CyclicLR(keras.callbacks.Callback):\n    \n    def __init__(self,base_lr, max_lr, step_size, base_m, max_m, cyclical_momentum):\n \n        self.base_lr = base_lr\n        self.max_lr = max_lr\n        self.base_m = base_m\n        self.max_m = max_m\n        self.cyclical_momentum = cyclical_momentum\n        self.step_size = step_size\n        \n        self.clr_iterations = 0.\n        self.cm_iterations = 0.\n        self.trn_iterations = 0.\n        self.history = {}\n        \n    def clr(self):\n        \n        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n        \n        if cycle == 2:\n            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)          \n            return self.base_lr-(self.base_lr-self.base_lr/100)*np.maximum(0,(1-x))\n        \n        else:\n            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0,(1-x))\n    \n    def cm(self):\n        \n        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n        \n        if cycle == 2:\n            \n            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1) \n            return self.max_m\n        \n        else:\n            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n            return self.max_m - (self.max_m-self.base_m)*np.maximum(0,(1-x))\n        \n        \n    def on_train_begin(self, logs={}):\n        logs = logs or {}\n\n        if self.clr_iterations == 0:\n            K.set_value(self.model.optimizer.lr, self.base_lr)\n        else:\n            K.set_value(self.model.optimizer.lr, self.clr())\n            \n        if self.cyclical_momentum == True:\n            if self.clr_iterations == 0:\n                K.set_value(self.model.optimizer.momentum, self.cm())\n            else:\n                K.set_value(self.model.optimizer.momentum, self.cm())\n            \n            \n    def on_batch_begin(self, batch, logs=None):\n        \n        logs = logs or {}\n        self.trn_iterations += 1\n        self.clr_iterations += 1\n\n        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n        self.history.setdefault('iterations', []).append(self.trn_iterations)\n        \n        if self.cyclical_momentum == True:\n            self.history.setdefault('momentum', []).append(K.get_value(self.model.optimizer.momentum))\n\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        \n        K.set_value(self.model.optimizer.lr, self.clr())\n        \n        if self.cyclical_momentum == True:\n            K.set_value(self.model.optimizer.momentum, self.cm())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 1 - обучение \"головы\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# Настройки\nbatch_size = BATCH_SIZE\nepochs = EPOCHS_STEP1\nbase_lr = LR_STEP1\nmax_lr = base_lr*10\nmax_m = MAX_MOMENTUM\nbase_m = BASE_MOMENTUM\n\ncyclical_momentum = CYCLICAL_MOMENTUM\naugment = AUGMENT\ncycles = CYCLES\n\n# Расчет количества итерация и шага изменения learning rate\niterations = round(train_generator.samples//train_generator.batch_size*epochs)\niterations = list(range(0,iterations+1))\nstep_size = len(iterations)/(cycles)\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=base_lr, momentum=BASE_MOMENTUM), metrics=[\"accuracy\"])\n\nclr =  CyclicLR(\n    base_lr=base_lr,\n    max_lr=max_lr,\n    step_size=step_size,\n    max_m=max_m,\n    base_m=base_m,\n    cyclical_momentum=cyclical_momentum\n)\n    \n# Добавим ModelCheckpoint чтоб сохранять прогресс обучения модели и можно было потом подгрузить и дообучить модель.    \ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='accuracy', patience=3, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop, clr]\n\n# Обучаем\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n    validation_data = test_generator, \n    validation_steps = test_generator.samples//test_generator.batch_size,\n    epochs = epochs,\n    callbacks = callbacks_list\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Смотрим, как изменялись learning rate и momentum в процессе обучения"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot Learning Rate\nimport matplotlib.pyplot as plt\nplt.plot(clr.history['iterations'], clr.history['lr'])\nplt.xlabel('Training Iterations')\nplt.ylabel('Learning Rate')\nplt.title(\"One Cycle Policy\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot momentum\nimport matplotlib.pyplot as plt\nplt.plot(clr.history['iterations'], clr.history['momentum'])\nplt.xlabel('Training Iterations')\nplt.ylabel('Momentum')\nplt.title(\"One Cycle Policy\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model)\nmodel.save('../working/model_step1.hdf5')\nmodel.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2 - FineTuning - обучение половины весов EfficientNetb6"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим на количество слоев в базовой модели\nprint(\"Number of layers in the base model: \", len(base_model.layers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Разморозим базовую модель\nbase_model.trainable = True\n\n# Установим количество слоев, которые будем переобучать\nfine_tune_at = len(base_model.layers)//2\n\n# Заморозим первую половину слоев\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Количество параметров\nlen(base_model.trainable_variables)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Статус слоев - будем обучать или нет\nfor layer in model.layers:\n    print(layer, layer.trainable)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Вновь обучаем модель, используя One Cycle Policy для Learning Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Настройки\n#batch_size = BATCH_SIZE\nepochs = EPOCHS_STEP2\nbase_lr = LR_STEP2\nmax_lr = base_lr*10\n#max_m = MAX_MOMENTUM\n#base_m = BASE_MOMENTUM\n\n#cyclical_momentum = CYCLICAL_MOMENTUM\n#augment = AUGMENT\n#cycles = CYCLES\n\n# Расчет количества итерация и шага изменения learning rate\niterations = round(train_generator.samples//train_generator.batch_size*epochs)\niterations = list(range(0,iterations+1))\nstep_size = len(iterations)/(cycles)\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=base_lr, momentum=BASE_MOMENTUM), metrics=[\"accuracy\"])\n\nclr =  CyclicLR(\n    base_lr=base_lr,\n    max_lr=max_lr,\n    step_size=step_size,\n    max_m=max_m,\n    base_m=base_m,\n    cyclical_momentum=cyclical_momentum\n)\n    \n# Добавим ModelCheckpoint чтоб сохранять прогресс обучения модели и можно было потом подгрузить и дообучить модель.    \n#checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\n#earlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop, clr]\n\n# Обучаем\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n    validation_data = test_generator, \n    validation_steps = test_generator.samples//test_generator.batch_size,\n    epochs = epochs,\n    callbacks = callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сохраним модель\nmodel.save('../working/model_step2.hdf5')\nmodel.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 3 - FineTuning - разморозка всей сети EfficientNetB6 и дообучение"},{"metadata":{},"cell_type":"markdown","source":"Разморозим базовую модель"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Повторно обучим модель, предварительно разморозив все слои"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Настройки\n#batch_size = BATCH_SIZE\nepochs = EPOCHS_STEP3\nbase_lr = LR_STEP3\nmax_lr = base_lr*10\n#max_m = MAX_MOMENTUM\n#base_m = BASE_MOMENTUM\n\n#cyclical_momentum = CYCLICAL_MOMENTUM\n#augment = AUGMENT\n#cycles = CYCLES\n\n# Расчет количества итерация и шага изменения learning rate\niterations = round(train_generator.samples//train_generator.batch_size*epochs)\niterations = list(range(0,iterations+1))\nstep_size = len(iterations)/(cycles)\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=base_lr, momentum=BASE_MOMENTUM), metrics=[\"accuracy\"])\n\nclr =  CyclicLR(\n    base_lr=base_lr,\n    max_lr=max_lr,\n    step_size=step_size,\n    max_m=max_m,\n    base_m=base_m,\n    cyclical_momentum=cyclical_momentum\n)\n    \n# Добавим ModelCheckpoint чтоб сохранять прогресс обучения модели и можно было потом подгрузить и дообучить модель.    \n#checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\n#earlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop, clr]\n\n# Обучаем\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n    validation_data = test_generator, \n    validation_steps = test_generator.samples//test_generator.batch_size,\n    epochs = epochs,\n    callbacks = callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('../working/model_step3.hdf5')\nmodel.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 4 - увеличение размера изображения"},{"metadata":{},"cell_type":"markdown","source":"Увеличим размер изображения и уменьшим уровень аугментации"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE             = IMG_SIZE_STEP4\nBATCH_SIZE           = BATCH_SIZE_STEP4\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    # albumentations.OneOf([\n    #     albumentations.CenterCrop(height=250, width=200),\n    #     albumentations.CenterCrop(height=200, width=250),\n    # ],p=0.5),\n    # albumentations.OneOf([\n    #     albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n    #     albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    # ],p=0.5),\n    # albumentations.GaussianBlur(p=0.05),\n    # albumentations.HueSaturationValue(p=0.5),\n    # albumentations.RGBShift(p=0.5),\n    # albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    # albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n\ntrain_datagen = ImageDataAugmentor(\n        rescale=1./255,\n        augment = AUGMENTATIONS,\n        validation_split=VAL_SPLIT,\n        )\n        \ntest_datagen = ImageDataAugmentor(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Заново создаем сеть с новым размером входных данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = efn.EfficientNetB7(weights='imagenet', include_top=False, input_shape=input_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Настройки\nbatch_size = BATCH_SIZE_STEP4\nepochs = EPOCHS_STEP4 + 5\nbase_lr = LR_STEP4\nmax_lr = base_lr*10\n#max_m = MAX_MOMENTUM\n#base_m = BASE_MOMENTUM\n\n#cyclical_momentum = CYCLICAL_MOMENTUM\n#augment = AUGMENT\n#cycles = CYCLES\n\n# Расчет количества итерация и шага изменения learning rate\niterations = round(train_generator.samples//train_generator.batch_size*epochs)\niterations = list(range(0,iterations+1))\nstep_size = len(iterations)/(cycles)\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=base_lr, momentum=BASE_MOMENTUM), metrics=[\"accuracy\"])\n\nmodel.load_weights('best_model.hdf5') # Подгружаем ранее обученные веса\n\nclr =  CyclicLR(\n    base_lr=base_lr,\n    max_lr=max_lr,\n    step_size=step_size,\n    max_m=max_m,\n    base_m=base_m,\n    cyclical_momentum=cyclical_momentum\n)\n    \n# Добавим ModelCheckpoint чтоб сохранять прогресс обучения модели и можно было потом подгрузить и дообучить модель.    \n#checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\n#earlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop, clr]\n\n# Обучаем\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n    validation_data = test_generator, \n    validation_steps = test_generator.samples//test_generator.batch_size,\n    epochs = epochs,\n    callbacks = callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('../working/model_step4.hdf5')\nmodel.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Предсказание на тестовых данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub_generator.samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Test Time Augmentation\nhttps://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d\n\nАугментируем тестовые изображения и сделаем несколько предсказаний одной картинки в разном виде.\nВзяв среднее значение из нескольких предсказаний получим итоговое предсказание."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=250, width=200),\n        albumentations.CenterCrop(height=200, width=250),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n      \ntest_datagen = ImageDataAugmentor( \n    rescale=1./255,\n    augment = AUGMENTATIONS,\n    validation_split=VAL_SPLIT,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tta_steps = 10 # берем среднее из 10 предсказаний\npredictions = []\n\nfor i in range(tta_steps):\n    preds = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \n    predictions.append(preds)\n\npred = np.mean(predictions, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.argmax(pred, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload/','')\nsubmission.to_csv('submission_TTA.csv', index=False)\nprint('Save submit')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Clean PATH\nimport shutil\nshutil.rmtree(PATH)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Итоги"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}